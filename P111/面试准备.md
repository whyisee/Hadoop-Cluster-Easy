---

title: "面试准备"
scp: 2019/11/27 23:35:40
tags:  

---


重点深入学习几点吧，其他了解
Hadoop MapReduce
原理，文件上传过程，理解MapReduce，手写MapReduce
Hive
原理，SQL执行过程，UDF，Mapreduce优化执行，调优
Hbase
原理，调优
Linux
脚本能力，常用命令的复杂用法
4个重点部分，其他的背下概念

1.数据库 oracle、mysql
2.实时处理 kafka，zookeeper，redis
3.语言Python。scala
4。工具 Git，maven，weblogic，tomcat，svn


# 熟悉 Hadoop 集群的搭建和基础配置，熟练使用 HDFS 及 MapReduce 实现功能
安装部署：
1.修改环境变量
2.ssh免密
3.修改打开文件个数，修改打开程序个数
4.修改配置文件
core-site.xml
配置临时文件目录
配置hdfs地址

hdfs-site.xml
配置namenode目录
配置datanode目录

yarn-site.xml
配置yarn.resourcemanager.hostname

mapred-site.xml
配置mapreduce工作

salves
主机节点

hdfs

mapreduce
分布式保证数据一致性
强一致性
所有机器状态就绪

弱一致性
用于处理海量数据的分布式计算框架
解决了

数据的分布存储  
作业调度  
容错  
机器间通信等复杂问题  

分治思想



2. 熟悉 Hive 原理， 熟悉 Hive SQL 语句及 UDF 的编写，了解 Hive 性能调优
hive是基于hadoop的数据仓库

1.数据是存储在hdfs上  
2.数据计算使用MapReduce

Hive是一种建立在Hadoop文件系统上的数据仓库架构，并可以对存储在HDFS上的数据进行分析和管理；  
可以将结构化的数据文件映射为一张数据库表，并提供完整的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。
通过自己的SQL去查询分析需要的内容，这套SQL简称Hive SQL（HQL），使不熟悉MapReduce的用户也能很方便的使用SQL语言  
对数据进行查询汇总分析。同时这个语言也允许熟悉MapReduce的开发者们开发自定义的Mappers和Reducers来处理复杂问题。  
Hive还允许用户编写自定义的函数UDF，用来在查询中使用。Hive有3中UDF，User Defined Function （UDF），User Defined  
Aggregation Function（UDAF），User Defined Table Generating Function（UDTF）。




3. 熟悉 HBase 的使用以及 HBase 集群的搭建，了解 HBase 底层存储原理
4. 熟悉 Oracle/MySQL 数据库， 熟练使用 Sqoop 数据传递。
5. 熟悉 java 基础知识， 了解线程池的基本原理
6. 熟悉 Java Web 基础， Html、 CSS、 jQurey 、 Layui 以及 HTTP 协议
7. 了解 Kafka 的消息处理模式， 了解 zookeeper 分布式服务框架
8. 了解 spark 的使用及部署， Spark SQL 的开发
9. 了解 python 和 scale 语言， 了解面向函数编程思想。
10. 了解 Redis Redis 集群，了解 Redis 的命令
11. 熟练使用 Linux 命令， 熟悉 shell 脚本。
12. 熟练使用 Svn/ Git/ CVS 开发项目
13. 熟悉 Maven 的使用，使用 Maven 的传递依赖继承机制搭建项目
14. 熟悉 Tomcat/Weblogic 容器